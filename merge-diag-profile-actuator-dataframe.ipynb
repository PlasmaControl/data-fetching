{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hollow-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import h5py\n",
    "import glob\n",
    "import cv2\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "compact-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "global main_data_path \n",
    "main_data_path = '/projects/EKOLEMEN/aza_lenny_data1/template/' \n",
    "\n",
    "all_shots = glob.glob('/scratch/gpfs/aj17/ece_co2/*.pkl') # This is just because we currently have CO2 data for some of the shots\n",
    "all_shots = [np.int(x[x.rfind('/')+1:x.rfind('.')]) for x in all_shots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adult-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_ece_co2(shotn,timing):\n",
    "    # Load ECE signals, extract spectrograms and store in a dataframe\n",
    "    spec_params={\n",
    "        'nperseg': 512, # default 1024\n",
    "        'noverlap': 256, # default: nperseg / 4\n",
    "        'fs': 500000, # raw signal sample rate is 4MHz\n",
    "        'window': 'hamm',\n",
    "        'scaling': 'density', # {'density', 'spectrum'}\n",
    "        'detrend': 'linear', # {'linear', 'constant', False}\n",
    "        'eps': 1e-11,\n",
    "        'enhanced':False # if True, the denoised spectrograms are stored\n",
    "    }        \n",
    "    all_data=dict()\n",
    "    fl_lst = glob.glob(main_data_path+'%i_ece*.h5' % (shotn))\n",
    "    if len(fl_lst) !=1:\n",
    "        print('Error in loading ECE data!')\n",
    "    else:\n",
    "        print('ECE data found!')\n",
    "        hf = h5py.File(fl_lst[0], 'r')\n",
    "        sig_time = np.asarray(hf['ece']['xdata'])\n",
    "        sig_time = np.where(np.logical_or(sig_time<timing['begin'],sig_time>timing['end']),np.nan,sig_time) # Cut everything beyond the timing['begin', 'end']\n",
    "        for ece_idx in range(40):\n",
    "            sig_data = np.asarray(hf['ece']['tecef%.2d' % (ece_idx+1)])\n",
    "            sig_data = sig_data[np.logical_not(np.isnan(sig_time))]\n",
    "            Sxx,f,t = specgr (sig_data,spec_params)\n",
    "            all_data['ece%.2d' % (ece_idx+1)]= pd.DataFrame(Sxx.T,columns=['ece%.2d_%d' % (ece_idx+1,x+1) for x in range(np.int32(spec_params['nperseg']/2))],index=t)\n",
    "        hf.close()\n",
    "        all_data['ece_freq'] = f\n",
    "\n",
    "\n",
    "    # Load CO2 signals, extract spectrograms and store in a dataframe\n",
    "    # It is very similar to ECE but just different h5 key names\n",
    "\n",
    "    spec_params={\n",
    "        'nperseg': 1024, # default 1024\n",
    "        'noverlap': 512, # default: nperseg / 4\n",
    "        'fs': 1670000, # raw signal sample rate is 4MHz\n",
    "        'window': 'hamm',\n",
    "        'scaling': 'density', # {'density', 'spectrum'}\n",
    "        'detrend': 'linear', # {'linear', 'constant', False}\n",
    "        'eps': 1e-11,\n",
    "        'enhanced':False # if True, the denoised spectrograms are stored\n",
    "    }\n",
    "    fl_lst = glob.glob(main_data_path+'%i_co2_pl.h5' % (shotn))\n",
    "    if len(fl_lst) !=1:\n",
    "        print('Error in loading CO2 data!')\n",
    "    else:\n",
    "        print('CO2 data found!')\n",
    "        hf = h5py.File(fl_lst[0], 'r')\n",
    "        sig_time = np.asarray(hf['co2_time'])\n",
    "        sig_time = np.where(np.logical_or(sig_time<timing['begin'],sig_time>timing['end']),np.nan,sig_time)\n",
    "        for co2_idx in ['r0','v1','v2','v3']:\n",
    "            sig_data = np.asarray(hf['pl1%s_uf' % (co2_idx)])\n",
    "            sig_data = sig_data[np.logical_not(np.isnan(sig_time))]\n",
    "            Sxx,f,t = specgr (sig_data,spec_params)\n",
    "            all_data[co2_idx]= pd.DataFrame(Sxx.T,columns=['%s_%d' % (co2_idx,x+1) for x in range(np.int32(spec_params['nperseg']/2))],index=t)\n",
    "\n",
    "        all_data['co2_freq'] = f            \n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "written-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_profiles_actuators(shotn,timing):\n",
    "    errflag=0\n",
    "    all_dfs=dict()\n",
    "    stats=dict()\n",
    "    for data_category in ['profiles','shape','pinj','tinj','qmin']:#Categories that can be found in separate files\n",
    "        hf = h5py.File(main_data_path+'%d_%s.h5' % (shotn,data_category), 'r')\n",
    "\n",
    "        for sig_name in hf.keys():\n",
    "            if np.sum(np.asarray(hf[sig_name]['ydata'])) == -1:\n",
    "                if len(np.asarray(hf[sig_name]['zdata']))<=1:\n",
    "                    print (print('<<<BAD!>>> %s: 1d signal' % (sig_name)))\n",
    "                    errflag=1\n",
    "                    continue\n",
    "                else:\n",
    "                    df = pd.DataFrame(np.asarray(hf[sig_name]['zdata']),index=np.asarray(hf[sig_name]['xdata']),columns=[sig_name])\n",
    "                    df.index.rename('time', inplace=True)\n",
    "            elif np.asarray(hf[sig_name]['xunits'])==b'ms':\n",
    "                df = pd.DataFrame(np.asarray(hf[sig_name]['zdata']),index=np.asarray(hf[sig_name]['xdata']),columns=[sig_name+str(x+1) for x in range(len(np.asarray(hf[sig_name]['ydata'])))])\n",
    "                df.index.rename('time', inplace=True)\n",
    "            elif np.asarray(hf[sig_name]['yunits'])==b'ms':\n",
    "                df = pd.DataFrame(np.asarray(hf[sig_name]['zdata']).T,index=np.asarray(hf[sig_name]['ydata']),columns=[sig_name+str(x+1) for x in range(len(np.asarray(hf[sig_name]['xdata'])))])\n",
    "                df.index.rename('time', inplace=True)\n",
    "            else:\n",
    "                print (print('<<<BAD!>>> %s: 2d signal' % (sig_name)))\n",
    "                errflag=1\n",
    "            df.drop(df[df.index < timing['begin']].index, inplace=True) #cut everything before given begin time\n",
    "            df.drop(df[df.index > timing['end']].index, inplace=True)#cut everything after given end time\n",
    "            all_dfs[sig_name]=df\n",
    "        hf.close()\n",
    "        # If only echpwrc is required, do not check the other ech signals\n",
    "        data_category = 'ech'\n",
    "        hf = h5py.File(main_data_path+'%d_%s.h5' % (shotn,data_category), 'r')\n",
    "        sig_name = 'echpwrc'\n",
    "        if np.sum(np.asarray(hf[sig_name]['ydata'])) == -1:\n",
    "            if len(np.asarray(hf[sig_name]['zdata']))<=1:\n",
    "                print (print('<<<BAD!>>> %s: 1d signal' % (sig_name)))\n",
    "                errflag=1\n",
    "                continue\n",
    "            else:\n",
    "                df = pd.DataFrame(np.asarray(hf[sig_name]['zdata']),index=np.asarray(hf[sig_name]['xdata']),columns=[sig_name])\n",
    "                df.index.rename('time', inplace=True)\n",
    "        elif np.asarray(hf[sig_name]['xunits'])==b'ms':\n",
    "            df = pd.DataFrame(np.asarray(hf[sig_name]['zdata']),index=np.asarray(hf[sig_name]['xdata']),columns=[sig_name+str(x+1) for x in range(len(np.asarray(hf[sig_name]['ydata'])))])\n",
    "            df.index.rename('time', inplace=True)\n",
    "        elif np.asarray(hf[sig_name]['yunits'])==b'ms':\n",
    "            df = pd.DataFrame(np.asarray(hf[sig_name]['zdata']).T,index=np.asarray(hf[sig_name]['ydata']),columns=[sig_name+str(x+1) for x in range(len(np.asarray(hf[sig_name]['xdata'])))])\n",
    "            df.index.rename('time', inplace=True)\n",
    "        else:\n",
    "            print (print('<<<BAD!>>> %s: 2d signal' % (sig_name)))\n",
    "            errflag=1\n",
    "        df.drop(df[df.index < timing['begin']].index, inplace=True)\n",
    "        df.drop(df[df.index > timing['end']].index, inplace=True)\n",
    "        all_dfs[sig_name]=df\n",
    "        hf.close()\n",
    "    return (all_dfs,stats)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "large-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual spectrogram extractor and enhacement pipeline\n",
    "def specgr (sig_in,spec_params,thr=0.9, gaussblr_win=(31,3)):\n",
    "    f, t, Sxx = scipy.signal.spectrogram(sig_in, nperseg=spec_params['nperseg'], noverlap=spec_params['noverlap'],fs=spec_params['fs'], window=spec_params['window'],scaling=spec_params['scaling'], detrend=spec_params['detrend'])\n",
    "    Sxx = np.log(Sxx + spec_params['eps'])\n",
    "    Sxx=(Sxx-np.min(Sxx))/(np.max(Sxx)-np.min(Sxx))\n",
    "    Sxx = Sxx[:-1,:];f=f[:-1]\n",
    "    if spec_params['enhanced']:\n",
    "        Sxx= quantfilt(Sxx,thr)\n",
    "        Sxx =  gaussblr(Sxx,gaussblr_win)\n",
    "        Sxx = meansub(Sxx)    \n",
    "        Sxx = morph(Sxx)\n",
    "        Sxx = meansub(Sxx)    \n",
    "    return Sxx,f,t*1000\n",
    "\n",
    "# ---- Spectrogram enahncement begin ----\n",
    "\n",
    "def norm(data):\n",
    "    mn = data.mean()\n",
    "    std = data.std()\n",
    "    return((data-mn)/std)\n",
    "\n",
    "def rescale(data):\n",
    "    return (data-data.min())/(data.max()-data.min())\n",
    "\n",
    "def quantfilt(src,thr=0.9):\n",
    "    filt = np.quantile(src,thr,axis=0)\n",
    "    out = np.where(src<filt,0,src)\n",
    "    return out\n",
    "\n",
    "# gaussian filtering\n",
    "def gaussblr(src,filt=(31, 3)):\n",
    "    src = (rescale(src)*255).astype('uint8')\n",
    "    out = cv2.GaussianBlur(src,filt,0)\n",
    "    return rescale(out)\n",
    "\n",
    "# mean filtering\n",
    "def meansub(src):\n",
    "    mn = np.mean(src,axis=1)[:,np.newaxis]\n",
    "    out = np.absolute(src - mn)\n",
    "    return rescale(out)\n",
    "\n",
    "# morphological filtering\n",
    "def morph(src):\n",
    "    src = (rescale(src)*255).astype('uint8')\n",
    "    se1 = cv2.getStructuringElement(cv2.MORPH_RECT, (4,4))\n",
    "    se2 = cv2.getStructuringElement(cv2.MORPH_RECT, (3,1))\n",
    "    mask = cv2.morphologyEx(src, cv2.MORPH_CLOSE, se1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se2)\n",
    "    return rescale(mask)\n",
    "# ---- Spectrogram enahncement end ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "difficult-warehouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE data found!\n",
      "CO2 data found!\n"
     ]
    }
   ],
   "source": [
    "shotn = all_shots[100]\n",
    "timing={'begin':0,\n",
    "       'end':4000\n",
    "       }\n",
    "ece_co2_data= create_data_ece_co2(shotn,timing) # Get ECE-CO2 dataframe\n",
    "final_df = pd.DataFrame(index=ece_co2_data['ece01'].index) # use the time of first channel of ECE as reference \n",
    "for df in [ece_co2_data['ece%.2d' % (idx+1)] for idx in range(40)]+[ece_co2_data[idx] for idx in ['r0','v1','v2','v3']]:\n",
    "    final_df=pd.merge_asof(final_df, df, left_index=True, right_index=True) #Merge all ECE-CO2 channel based on the time of ECE01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "official-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_act_data,prof_act_stats = create_data_profiles_actuators(shotn,timing) #Get profile-actuator dataframe\n",
    "feat_list=[  'bmspinj' #Select which columns to be merged as the final dataframe\n",
    "            ,'bmstinj'\n",
    "            ,'pcbcoil'\n",
    "            ,'iptipp'\n",
    "            ,'kappa'\n",
    "            ,'triangularity_u'\n",
    "            ,'triangularity_l'\n",
    "            ,'echpwrc'\n",
    "          ]+['pinjf_%s%s' % (pw,sd) for pw in ['15','21','30','33'] for sd in ['l','r']]+['tinj_%s%s' % (pw,sd) for pw in ['15','21','30','33'] for sd in ['l','r']]\n",
    "for feat in feat_list:\n",
    "    final_df=pd.merge_asof(final_df, prof_act_data[feat], left_index=True, right_index=True) # merge the selected columns of profil-actuator to ECE-CO2\n",
    "\n",
    "pickle.dump(final_df,open('temp.pkl','wb')) # dump the final dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
